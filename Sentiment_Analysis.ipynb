{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxnfTEbXzzctl+v8oijmRb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivanshBhagria/Projects/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the libraries"
      ],
      "metadata": {
        "id": "xE5yG-Qq1S6D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkL5hYzm1LAe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dataset"
      ],
      "metadata": {
        "id": "x2S4LaIN1g53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('Restaurant_Reviews.tsv',delimiter='\\t',quoting=3)"
      ],
      "metadata": {
        "id": "WJuz0U_k1jYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The quoting parameter in pd.read_csv is used to control how quotes in the data are handled. In your code, quoting=3 corresponds to csv.QUOTE_NONE, which means that no quotes will be recognized in the input file. This is useful when you are sure that your data does not contain any quoted fields that need special handling."
      ],
      "metadata": {
        "id": "KHjMZvdG3GIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the texts"
      ],
      "metadata": {
        "id": "1G2Gs5ys3ISH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus=[]\n",
        "for i in range(0,1000):\n",
        "  review=re.sub('[^a-zA-Z]',' ',dataset['Review'][i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  ps=PorterStemmer()\n",
        "  all_stopwords=stopwords.words('english')\n",
        "  all_stopwords.remove('not')\n",
        "  review=[ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
        "  # review=[word for word in review if not word in set(all_stopwords)]\n",
        "  review=' '.join(review)\n",
        "  corpus.append(review)\n",
        "print(corpus)"
      ],
      "metadata": {
        "id": "Jgt9MKHb3Lp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the bag of wors model"
      ],
      "metadata": {
        "id": "PZFJfiypuSob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "X=cv.fit_transform(corpus).toarray()\n",
        "y=dataset.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "6NMTtV18uXY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset into the training set and test set"
      ],
      "metadata": {
        "id": "13jN-ByMvqd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)"
      ],
      "metadata": {
        "id": "zRui-cS0vvdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Naive Nayes model on the training set"
      ],
      "metadata": {
        "id": "Af7GFv2dwvAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier=GaussianNB()\n",
        "classifier.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Mz63GIYnw3cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "0xbiSbeWbqAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "plbBXwIkdDSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the test set results"
      ],
      "metadata": {
        "id": "xQFKKFRtxK3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=classifier.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "11yeL83PxSBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making the confusion matrix"
      ],
      "metadata": {
        "id": "IVc8siDNzaO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "e5IFMzTbzczv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test,clf.predict(X_test))"
      ],
      "metadata": {
        "id": "YDtRDNBncQ_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test,svm.predict(X_test))"
      ],
      "metadata": {
        "id": "0_vpRM-MdPxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "id": "OWK7YMEO1ya2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting if a single review is positive or neagtive"
      ],
      "metadata": {
        "id": "ndaJtlWD14bX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positive review"
      ],
      "metadata": {
        "id": "zR0iQGhi2CTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use our model to predict if the following review:\n",
        "\n",
        "\"I love this restaurant so much\"\n",
        "\n",
        "is positive or negative."
      ],
      "metadata": {
        "id": "BM36cv2k2Gge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution: We just repeat the same text preprocessing process we did before, but this time with a single review."
      ],
      "metadata": {
        "id": "j6BCQ3FJ2Jns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_review='I love this restaurant so much'\n",
        "new_review=re.sub('[^a-zA-Z]',' ',new_review)\n",
        "new_review=new_review.lower()\n",
        "new_review=new_review.split()\n",
        "ps=PorterStemmer()\n",
        "all_stopwords=stopwords.words('english')\n",
        "all_stopwords.remove('not')\n",
        "new_review=[ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
        "new_review=' '.join(new_review)\n",
        "new_corpus=[new_review]\n",
        "new_X_test=cv.transform(new_corpus).toarray()\n",
        "new_y_pred=classifier.predict(new_X_test)\n",
        "print(new_y_pred)"
      ],
      "metadata": {
        "id": "D8TSs1UD1-vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The review was correctly predicted as positive by our model.\n",
        "\n"
      ],
      "metadata": {
        "id": "duSjvzX84gKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Negative review"
      ],
      "metadata": {
        "id": "SrLvP7G34hNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use our model to predict if the following review:\n",
        "\n",
        "\"I hate this restaurant so much\"\n",
        "\n",
        "is positive or negative."
      ],
      "metadata": {
        "id": "VdGFQVfl4mV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution: We just repeat the same text preprocessing process we did before, but this time with a single review."
      ],
      "metadata": {
        "id": "mgoxhCj44sZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_review = 'I hate this restaurant so much'\n",
        "new_review = re.sub('[^a-zA-Z]', ' ', new_review)\n",
        "new_review = new_review.lower()\n",
        "new_review = new_review.split()\n",
        "ps = PorterStemmer()\n",
        "all_stopwords = stopwords.words('english')\n",
        "all_stopwords.remove('not')\n",
        "new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]\n",
        "new_review = ' '.join(new_review)\n",
        "new_corpus = [new_review]\n",
        "new_X_test = cv.transform(new_corpus).toarray()\n",
        "new_y_pred = classifier.predict(new_X_test)\n",
        "print(new_y_pred)"
      ],
      "metadata": {
        "id": "VwqIeZFg4t3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The review was correctly predicted as negative by our model."
      ],
      "metadata": {
        "id": "Aj4R0wxY4yyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "id": "ro-nbTOLhYZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "id": "BuF8J-LxhkLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(review)"
      ],
      "metadata": {
        "id": "2VgsZLwtheE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(review)"
      ],
      "metadata": {
        "id": "Zz1X7irkhhJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "SzHhAeaUhwc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "oSTjlRPTh0kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "id": "-fKGnJamh9XI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}